{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IN3050/IN4050 Mandatory Assignment 2: Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name: Danielius Kocan (danielik)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules\n",
    "\n",
    "Before you begin the exercise, review the rules at this website: https://www.uio.no/english/studies/examinations/compulsory-activities/mn-ifi-mandatory.html , in particular the paragraph on cooperation. This is an individual assignment. You are not allowed to deliver together or copy/share source-code/answers with others. Read also the \"Routines for handling suspicion of cheating and attempted cheating at the University of Oslo\" https://www.uio.no/english/about/regulations/studies/studies-examinations/routines-cheating.html By submitting this assignment, you confirm that you are familiar with the rules and the consequences of breaking them.\n",
    "\n",
    "### Delivery\n",
    "\n",
    "**Deadline**: Friday, March 19, 2021, 23:59\n",
    "\n",
    "Your submission should be delivered in Devilry. You may redeliver in Devilry before the deadline, but include all files in the last delivery, as only the last delivery will be read. You are recommended to upload preliminary versions hours (or days) before the final deadline.\n",
    "\n",
    "### What to deliver?\n",
    "\n",
    "You are recommended to solve the exercise in a Jupyter notebook, but you might solve it in a Python program if you prefer.\n",
    "\n",
    "If you choose Jupyter, you should deliver the notebook. You should answer all questions and explain what you are doing in Markdown. Still, the code should be properly commented. The notebook should contain results of your runs. In addition, you should make a pdf of your solution which shows the results of the runs.\n",
    "\n",
    "If you prefer not to use notebooks, you should deliver the code, your run results, and a pdf-report where you answer all the questions and explain your work.\n",
    "\n",
    "Your report/notebook should contain your name and username.\n",
    "\n",
    "Deliver one single zipped folder (.zip, .tgz or .tar.gz) which contains your complete solution.\n",
    "\n",
    "Important: if you weren’t able to finish the assignment, use the PDF report/Markdown to elaborate on what you’ve tried and what problems you encountered. Students who have made an effort and attempted all parts of the assignment will get a second chance even if they fail initially. This exercise will be graded PASS/FAIL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals of the exercise\n",
    "This exercise has three parts. The goal of the first part is to get more experience with supervised classification. We will use simple synthetic datasets and focus on the learning algorithms. \n",
    "\n",
    "The goal of the second part is to consider the implementaion of the  Multi-layer feed forward neural network, often called Multi-layer perceptron (MLP).\n",
    "\n",
    "The third part, which is the smallest one, is dedicated to evaluation.\n",
    "\n",
    "### Tools\n",
    "The aim of the exercises is to give you a look inside the learning algorithms. You may freely use code from the weekly exercises and the published solutions. You should not use ML libraries like scikit-learn or tensorflow.\n",
    "\n",
    "You may use tools like NumPy and Pandas, which are not specific ML-tools.\n",
    "\n",
    "### Beware\n",
    "There might occur typos or ambiguities. If anything is unclear, do not hesitate to ask. Also, if you think some assumptions are missing, make your own and explain them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Comparing classifiers\n",
    "## Datasets\n",
    "We start by making a synthetic dataset of 1600 datapoints and three classes, with 800 individuals in one class and 400 in each of the two other classes. (See https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html#sklearn.datasets.make_blobs regarding how the data are generated.)\n",
    "\n",
    "When we are doing experiments in supervised learning, and the data are not already split into training and test sets, we should start by splitting the data. Sometimes there are natural ways to split the data, say training on data from one year and testing on data from a later year, but if that is not the case, we should shuffle the data randomly before splitting. (OK, that is not necessary with this particular synthetic data set, since it is already shuffled by default by scikit, but that will not be the case with real-world data.) We should split the data so that we keep the alignment between X and t, which may be achieved by shuffling the indices. We split into 50% for training, 25% for validation, and 25% for final testing. The set for final testing *must not be used* till the end of the assignment in part 3.\n",
    "\n",
    "We fix the seed both for data set generation and for shuffling, so that we work on the same datasets when we rerun the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "X, t = make_blobs(n_samples=[400,800,400], centers=[[0,0],[1,2],[2,3]], \n",
    "                  n_features=2, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1301,  293,  968,  624,  658,  574,  433,  368,  512,  353])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.arange(X.shape[0])\n",
    "random.seed(2020)\n",
    "random.shuffle(indices)\n",
    "indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[indices[:800],:]\n",
    "X_val = X[indices[800:1200],:]\n",
    "X_test = X[indices[1200:],:]\n",
    "t_train = t[indices[:800]]\n",
    "t_val = t[indices[800:1200]]\n",
    "t_test = t[indices[1200:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will  make a second dataset by merging the two smaller classes in (X,t) and call the new set (X, t2). This will be a binary set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_train = t_train == 1\n",
    "t2_train = t2_train.astype('int')\n",
    "t2_val = (t_val == 1).astype('int')\n",
    "t2_test = (t_test == 1).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the two training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from weekly task solution\n",
    "def show(X, y, marker='.'):\n",
    "    \"\"\"\n",
    "    With set X and labels y, plots the points with a different colors for each class on the plot. \n",
    "    \n",
    "    Args:\n",
    "        X(numpy ndarray): Set, where each index is the position on the plot\n",
    "        y(numpy array):   Lable for each instance in X\n",
    "    \"\"\"\n",
    "    plt.figure() # to make it plot on new figure\n",
    "    labels = set(y)\n",
    "    cl = {lab : [] for lab in labels}\n",
    "    # cl[lab] shall contain the datapoints labeled lab\n",
    "    for (a, b) in zip(X, y):\n",
    "        cl[b].append(a)\n",
    "    for lab in labels:\n",
    "        plt.plot([a[0] for a in cl[lab]], [a[1] for a in cl[lab]], \n",
    "                 marker, label=\"class {}\".format(lab))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(X_train, t_train)\n",
    "show(X_train, t2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "We see that that set (X, t2) is far from linearly separable, and we will explore how various classifiers are able to handle this. We start with linear regression. You may use the implementation from exercise set week07 or make your own. You should make one improvement. The implementation week07 runs for a set number of epochs. You provide the number of epochs with a parameter to the fit-method. However, you do not know what a reasonable number of epochs is. Add one more argument to the fit-method *diff* (with defualt value e.g. 0.001). The training should stop when the update is less than *diff*. The *diff* will save training time, but it may also be wise to not set it too small -- and not run training for too long -- to avoid overfitting.\n",
    "\n",
    "Train the classifier on (X_train, t2_train) and test for accuracy on (X_val, t2_val) for various values of *diff*. Choose what you think is optimal *diff*. Report accuracy and save it for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates mean square error\n",
    "    \n",
    "    Args:\n",
    "        y(numpy ndarray):          Set, where each index is the position on the plot\n",
    "        y_pred(numpy array):       Lable for each instance in X\n",
    "    Returns:\n",
    "        mean_squared_error(float): Mean square error\n",
    "    \"\"\"\n",
    "    sum_errors = 0.\n",
    "    for i in range(0,len(y)):\n",
    "        sum_errors += (y[i] - y_pred[i])**2\n",
    "    mean_squared_error = sum_errors/len(y)\n",
    "    return mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias(X):\n",
    "    \"\"\"\n",
    "    Adds a bias in index 0 in X ndarray.\n",
    "    \n",
    "    Args:\n",
    "        X(numpy ndarray): Ndarray that we will add bias to\n",
    "    Returns:\n",
    "        _(numpy ndarray): Array with the added bias\n",
    "    \"\"\"\n",
    "    # Put bias in position 0\n",
    "    sh = X.shape\n",
    "    if len(sh) == 1:\n",
    "        #X is a vector\n",
    "        return np.concatenate([np.array([1]), X])\n",
    "    else:\n",
    "        # X is a matrix\n",
    "        m = sh[0]\n",
    "        bias = np.ones((m,1)) # Makes a m*1 matrix of 1-s\n",
    "        return np.concatenate([bias, X], axis  = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyClassifier():\n",
    "    \"\"\"Common methods to all numpy classifiers --- if any\"\"\"\n",
    "    \n",
    "    def accuracy(self,X_test, y_test, **kwargs):\n",
    "        pred = self.predict(X_test, **kwargs)\n",
    "        if len(pred.shape) > 1:\n",
    "            pred = pred[:,0]\n",
    "        return sum(pred==y_test)/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation from week 7 tasks\n",
    "class NumpyLinRegClass(NumpyClassifier):\n",
    "\n",
    "    def fit(self, X_train, t_train, eta = 0.1, diff=0.001):\n",
    "        \"\"\"X_train is a Nxm matrix, N data points, m features\n",
    "        t_train are the targets values for training data\"\"\"\n",
    "        \n",
    "        (k, m) = X_train.shape\n",
    "        X_train = add_bias(X_train)\n",
    "        self.weights = weights = np.zeros(m+1)\n",
    "        curDiff = 1\n",
    "        \n",
    "        while curDiff > diff:\n",
    "            oldError = mse(t_train, X_train @ weights)\n",
    "            weights -= eta / k *  X_train.T @ (X_train @ weights - t_train)      \n",
    "            newError = mse(t_train, X_train @ weights)\n",
    "            curDiff = oldError - newError\n",
    "            \n",
    "            \n",
    "    def predict(self, x, threshold=0.5):\n",
    "        \"\"\"Predict the value for the item x\"\"\"\n",
    "        z = add_bias(x)\n",
    "        score = z @ self.weights\n",
    "        return score>threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_cl = NumpyLinRegClass()\n",
    "lin_cl.fit(X_train, t2_train, 0.1, 0.000001)\n",
    "lin_cl.accuracy(X_val, t2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "Do the same for logistic regression, i.e., add the *diff*, tune it, report accuracy, and store it for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Implementation from week 7 tasks\n",
    "class NumpyLogReg(NumpyClassifier):\n",
    "\n",
    "    def fit(self, X_train, t_train, eta = 0.1, diff=0.001):\n",
    "        \"\"\"X_train is a Nxm matrix, N data points, m features\n",
    "        t_train are the targets values for training data\"\"\"\n",
    "        \n",
    "        (k, m) = X_train.shape\n",
    "        X_train = add_bias(X_train)\n",
    "        \n",
    "        self.weights = weights = np.zeros(m+1)\n",
    "        curDiff = 1\n",
    "        \n",
    "        while curDiff > diff:\n",
    "            oldError = mse(t_train, X_train @ weights)\n",
    "            weights -= eta / k *  X_train.T @ (self.forward(X_train) - t_train)     \n",
    "            newError = mse(t_train, X_train @ weights)\n",
    "            curDiff = oldError - newError      \n",
    "    \n",
    "    def forward(self, X):\n",
    "        return logistic(X @ self.weights)\n",
    "    \n",
    "    def score(self, x):\n",
    "        z = add_bias(x)\n",
    "        score = self.forward(z)\n",
    "        return score\n",
    "    \n",
    "    def predict(self, x, threshold=0.5):\n",
    "        \"\"\"Predict the value for the item x\"\"\"\n",
    "        z = add_bias(x)\n",
    "        score = self.forward(z)\n",
    "        return (score>threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cl = NumpyLogReg()\n",
    "lr_cl.fit(X_train, t2_train, 0.1, 0.001)\n",
    "lr_cl.accuracy(X_val, t2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *k*-nearest neighbors (*k*NN)\n",
    "We will now compare to the *k*-nearest neighbors classifier. You may use the implementation from the week05 exercise set. Beware, though, that we represented the data differently from what we do here, using Python lists instead of numpy arrays. You might have to either modify the representation of the data or the code a little.\n",
    "\n",
    "Train on (X_train, t2_train) and test on (X2_val, t2_val) for various values of *k*. Choose the best *k*, report accuracy and store for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def distance_L2(a, b):\n",
    "    \"L2-distance using comprehension\"\n",
    "    s = sum((x - y) ** 2 for (x,y) in zip(a,b))\n",
    "    return s ** 0.5\n",
    "\n",
    "def majority(a):\n",
    "    counts = Counter(a)\n",
    "    return counts.most_common()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation from week 5 task\n",
    "class PyClassifier():\n",
    "    \"\"\"Common methods to all python classifiers --- if any\"\"\"\n",
    "    \n",
    "    def accuracy(self,X_test, y_test, **kwargs):\n",
    "        \"\"\"Calculate the accuracy of the classifier \n",
    "        using the predict method\"\"\"\n",
    "        predicted = [self.predict(a, **kwargs) for a in X_test]\n",
    "        equal = len([(p, g) for (p,g) in zip(predicted, y_test) if p==g])\n",
    "        return equal / len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PykNNClassifier(PyClassifier):\n",
    "    \"\"\"kNN classifier using pure python representations\"\"\"\n",
    "    \n",
    "    def __init__(self, k=3, dist=distance_L2):\n",
    "        self.k = k\n",
    "        self.dist = dist\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def predict(self, a):\n",
    "        \"\"\"Predict the value for the item x\"\"\"\n",
    "        X = self.X_train\n",
    "        y = self.y_train\n",
    "        distances = [(self.dist(a, b), b, c) for (b, c) in zip(X, y)]\n",
    "        distances.sort()\n",
    "        predictors = [c for (_,_,c) in distances[0: self.k]]\n",
    "        return majority(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best kNN accuracy: 0.7675 is for k = 14. (Range: 1 to 20)\n"
     ]
    }
   ],
   "source": [
    "bestAcc = 0\n",
    "k = 0\n",
    "for i in range(1, 20):\n",
    "    cls = PykNNClassifier(k=i)\n",
    "    cls.fit(X_train.tolist(), t2_train.tolist())\n",
    "    acc = cls.accuracy(X_val.tolist(), t2_val.tolist())\n",
    "    if acc > bestAcc:\n",
    "        bestAcc = acc \n",
    "        k = i\n",
    "\n",
    "print(f\"Best kNN accuracy: {bestAcc} is for k = {k}. (Range: 1 to 20)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple perceptron\n",
    "Finally, run the simple perceptron (week06) on the same set, and report and store accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyPerClassifier(PyClassifier):\n",
    "    \"\"\"Simple perceptron python classifier\"\"\"\n",
    "    \n",
    "    def fit(self, X_train, y_train, eta=1, epochs=1):\n",
    "        \"\"\"Train the self.weights on the training data with learning\n",
    "        rate eta, running epochs many epochs\"\"\"\n",
    "        X_train = [[1]+list(x) for x in X_train] # Put bias in position 0      \n",
    "        self.dim = dim = len(X_train[0])\n",
    "        self.weights = weights = [0 for _ in range(dim)]\n",
    "        # Initialize all weights to 0.\n",
    "        for e in range(epochs):\n",
    "            for x, t in zip(X_train, y_train):\n",
    "                y = int(self.forward(x)>0)\n",
    "                for i in range(dim):\n",
    "                    weights[i] -= eta * (y - t) * x[i]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Calculate the score for the item x\"\"\"\n",
    "        score = sum([self.weights[i]*x[i] for i in range(self.dim)])\n",
    "        return score       \n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"Predict the value for the item x\"\"\"\n",
    "        x = [1] + list(x)\n",
    "        score = self.forward(x)\n",
    "        return int(score > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best perceptron accuracy: 0.6625 is after 17 epoch. (Range: 1 to 25)\n"
     ]
    }
   ],
   "source": [
    "bestAcc = 0\n",
    "epoch = 0\n",
    "for i in range(1,25):\n",
    "    cl = PyPerClassifier()\n",
    "    cl.fit(X_train.tolist(), t2_train.tolist(), eta= 0.1, epochs = i)\n",
    "    acc = cl.accuracy(X_val.tolist(), t2_val.tolist())\n",
    "    if acc > bestAcc:\n",
    "        bestAcc = acc\n",
    "        epoch = i\n",
    "        \n",
    "print(f\"Best perceptron accuracy: {bestAcc} is after {epoch} epoch. (Range: 1 to 25)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "Report the accuracies for the four classifiers in a table.\n",
    "\n",
    "Write a couple of sentences where you comment on what you see. Are the results as you expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Classifier | Accuracy |\n",
    "| --- | --- |\n",
    "| Linear regression | 0.6 |\n",
    "| Logistic regression | 0.6 |\n",
    "| kNN | 0.7675 |\n",
    "| Simple perceptron | 0.6625 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like best accuracy is for k-nearest neighbors. It is actually what I expected. \n",
    "\n",
    "I didn't had any hope for linear regression and logistic regression, because from the plot above it is easy to see that data is not well suitable for linear/logistic classifiers. Moreover we had to classes in test2, and they didn't had good separation, so it is hard to find a good position for line.\n",
    "\n",
    "I was also expecting that Simple perceptron will be very close to the Linear/Logistic regression, because simple perceptron is a type of linear classifier. However it does not look that that. The result for Simple perceptron is better than for logistic/linear regression. So this is kind of weird for me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classifiers\n",
    "We turn to the task of classifying when there are more than two classes, and the task is to ascribe one class to each input. We will now use the set (X, t)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *k*NN\n",
    "One of the classifiers can handle multiple classes without modifications: the *k*-nearest neighbors classifier. Train it on (X_train, t_train), test it on (X_val, t_val) for various values of *k*. Choose the one you find best and report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best kNN accuracy: 0.77 is for k = 14. (Range: 1 to 20)\n"
     ]
    }
   ],
   "source": [
    "bestAcc = 0\n",
    "k = 0\n",
    "for i in range(1, 20):\n",
    "    cls = PykNNClassifier(k=i)\n",
    "    cls.fit(X_train.tolist(), t_train.tolist())\n",
    "    acc = cls.accuracy(X_val.tolist(), t_val.tolist())\n",
    "    if acc > bestAcc:\n",
    "        bestAcc = acc \n",
    "        k = i\n",
    "\n",
    "print(f\"Best kNN accuracy: {bestAcc} is for k = {k}. (Range: 1 to 20)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression \"one-vs-rest\"\n",
    "We saw in the lecture how a logistic regression classifier can be turned into a multi-class classifier using the one-vs-rest approach. We train one classifier for each class and assign the class which ascribes the highest probability.\n",
    "\n",
    "Extend the logisitc regression classifier to a multi-class classifier. To do this, you must modify the target values from scalars to arrays. Train the resulting classifier on (X_train, t_train), test it on (X_val, t_val), and report the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it work, I need, for each class, make other classes as the same class. So if we have 3 classes. First trained classifier will be for class 1 while class 2 and 3 is the same class (so it is like to have 2 classes). Second trained classifier will be for class 2 while class 1 and 3 is the same class. Last trained classifier will be class 3 while class 1 and 2 is the same class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 accuracy: 0.81\n",
      "Class 1 accuracy: 0.6\n",
      "Class 2 accuracy: 0.7425\n",
      "Avarage accuracy for Logistic Regression: 0.7175000000000001\n"
     ]
    }
   ],
   "source": [
    "# We have data with 3 classes for train and valuation:\n",
    "# X_train, X_val.\n",
    "# t_train, t_val.\n",
    "# show(X_train, t_train)\n",
    "\n",
    "all_acc = []\n",
    "for i in set(t_train): # so it can work for any number of classes, not only 3.\n",
    "    lr_cl = NumpyLogReg()\n",
    "    # This part of the code is from the given precode in this assignment.\n",
    "    tnew_train = (t_train == i).astype('int')\n",
    "    tnew_val = (t_val == i).astype('int')\n",
    "    #show(X_train, tnew_train) # for testing\n",
    "    lr_cl.fit(X_train, tnew_train, 0.1, 0.001)\n",
    "    acc = lr_cl.accuracy(X_val, tnew_val)\n",
    "    all_acc.append(acc)\n",
    "\n",
    "    print(f\"Class {i} accuracy: {acc}\")\n",
    "    \n",
    "print(f\"Avarage accuracy for Logistic Regression: {sum(all_acc)/len(all_acc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the results in a couple of sentences, addressing questions like\n",
    "\n",
    "- How do the two classfiers compare?\n",
    "- How do the results on the three-class classification task compare to the results on the binary task?\n",
    "- What do you think are the reasons for the differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - kNN had better accuracy, with 0.05 more than Logistic regression. I think reason for that is that for some classes accuracy is worse than for others, as we can see from the results (Class 1 acc: 0.6, however class 0 acc: 0.81). This is because data for class 1 is located in between class 0 and class 2.\n",
    "    - kNN had a little better accuracy with three-class classification, than with binary. However I can say that both are almost equal. Moreover logistic regression did a bit better too (If I calculated total accuracy right). Because One-vs-Rest is like a binary classifier but multiple times.\n",
    "    - I think the reason for that kNN have almost identical accuracy is that it is good suited for any number of classes. Because we use the same method for any number of classes. But for One-vs-Rest we will get sometimes bad accuracy for some classes, and maybe better accuracy for some other classes. The position of \"main\" class and all other classes can play a big role in that.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding non-linear features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are returning to the binary classifier and the set (X, t2). As we see, some of the classifiers are not doing too well on the (X, t2) set. It is easy to see from the plot that this data set is not well suited for linear classifiers. There are several possible options for trying to learn on such a set. One is to construct new features from the original features to get better discriminants. This works e.g., for the XOR-problem. The current classifiers use two features: $x_1$ and $x_2$ (and a bias term $x_0$). Try to add three additional features of the form ${x_1}^2$, ${x_2}^2$, $x_1*x_2$ to the original features and see what the accuracies are now. Compare to the results for the original features in a 4x2 table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression: 0.7325\n",
      "Logistic regression: 0.52\n",
      "Best kNN accuracy: 0.7525 is for k = 13. (Range: 1 to 20)\n",
      "Best perceptron accuracy: 0.6275 is after 38 epoch. (Range: 1 to 40)\n"
     ]
    }
   ],
   "source": [
    "def addNewFeatures(ndarr):\n",
    "    \"\"\"Adds new features\"\"\"\n",
    "    \n",
    "    x1_sq = ndarr[:,0]**2\n",
    "    x2_sq = ndarr[:,1]**2\n",
    "    x1x2 = np.multiply(x1_sq,x2_sq)\n",
    "    \n",
    "    x1_sq = x1_sq.reshape(x1_sq.shape + (1,))\n",
    "    x2_sq = x2_sq.reshape(x2_sq.shape + (1,))\n",
    "    x1x2 = x1x2.reshape(x1x2.shape + (1,))\n",
    "    \n",
    "    ret_arr = ndarr\n",
    "    ret_arr = np.append(ret_arr, x1_sq, axis=1)\n",
    "    ret_arr = np.append(ret_arr, x2_sq, axis=1)\n",
    "    ret_arr = np.append(ret_arr, x1x2, axis=1)\n",
    "    \n",
    "    return ret_arr\n",
    "    \n",
    "\n",
    "# Creating new datasets by adding new features\n",
    "Xnew_train = addNewFeatures(X_train)\n",
    "Xnew_val = addNewFeatures(X_val)\n",
    "\n",
    "# Linear regression\n",
    "lin_cl = NumpyLinRegClass()\n",
    "lin_cl.fit(Xnew_train, t2_train, 0.001, 0.00001) # changed learning rate\n",
    "print(f\"Linear regression: {lin_cl.accuracy(Xnew_val, t2_val)}\")\n",
    "\n",
    "# Logistic regression\n",
    "lr_cl = NumpyLogReg()\n",
    "lr_cl.fit(Xnew_train, t2_train, 0.1, 0.1)\n",
    "print(f\"Logistic regression: {lr_cl.accuracy(Xnew_val, t2_val)}\")\n",
    "\n",
    "# kNN\n",
    "bestAcc = 0\n",
    "k = 0\n",
    "for i in range(1, 20):\n",
    "    cls = PykNNClassifier(k=i)\n",
    "    cls.fit(Xnew_train.tolist(), t2_train.tolist())\n",
    "    acc = cls.accuracy(Xnew_val.tolist(), t2_val.tolist())\n",
    "    if acc > bestAcc:\n",
    "        bestAcc = acc \n",
    "        k = i\n",
    "\n",
    "print(f\"Best kNN accuracy: {bestAcc} is for k = {k}. (Range: 1 to 20)\")\n",
    "\n",
    "# Simple perceptron\n",
    "bestAcc = 0\n",
    "epoch = 0\n",
    "for i in range(1,40):\n",
    "    cl = PyPerClassifier()\n",
    "    cl.fit(Xnew_train.tolist(), t2_train.tolist(), eta= 0.1, epochs = i)\n",
    "    acc = cl.accuracy(Xnew_val.tolist(), t2_val.tolist())\n",
    "    if acc > bestAcc:\n",
    "        bestAcc = acc\n",
    "        epoch = i\n",
    "        \n",
    "print(f\"Best perceptron accuracy: {bestAcc} is after {epoch} epoch. (Range: 1 to 40)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Classifier | Accuracy | Change |\n",
    "| --- | --- | --- |\n",
    "| Linear regression | 0.7325 | higher |\n",
    "| Logistic regression | 0.52 | lower |\n",
    "| kNN | 0.7525 | lower |\n",
    "| Simple perceptron | 0.6275 | lower |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain in a couple of sentences what effect the non-linear features have on the various classifiers. (By the way, some of the classifiers could probably achieve better results if we scaled the data, but we postpone scaling to part 2 of the assignment.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression did very well. However I had to change learning rate in linear regression, from 0.1 to 0.001, to make it more accurate. It runs slower but it have more accurate answer. \n",
    "\n",
    "All others classifiers lost a bit in accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II\n",
    "## Multi-layer neural networks\n",
    "We will implement the Multi-layer feed forward network (MLP, Marsland sec. 4.2.1). We will do so in two steps. In the first step, we will work concretely with the dataset (X, t). We will initialize the network and run a first round of training, i.e. one pass throught the algorithm at p. 78 in Marsland.\n",
    "\n",
    "In the second step, we will turn this code into a more general classifier. We can train and test this on (X, t), but also on other datasets.\n",
    "\n",
    "First of all, you should scale the X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling of X_train\n",
    "# From Normalization and Standarization, I decided to use min-max normalization.\n",
    "x_max = np.max(X_train)\n",
    "x_min = np.min(X_train)\n",
    "X_train_scaled = (X_train - x_min)/(x_max - x_min)\n",
    "# show(X_train, t_train) # for test\n",
    "# show(X_train_scaled, t_train) # for test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: One round of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "We will only use one hidden layer. The number of nodes in the hidden layer will be a hyper-parameter provided by the user; let's call it *dim_hidden*. (*dim_hidden* is called *M* by Marsland.) Initially, we will set it to 6. This is a hyper-parameter where other values may give better results, and the hyper-parameter could be tuned.\n",
    "\n",
    "Another hyper-parameter set by the user is the learning rate. We set the initial value to 0.01, but also this may need tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.01 # Learning rate\n",
    "dim_hidden = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the input *X_train* (after scaling) is a matrix of dimension *P x dim_in*, where *P* is the number of training instances, and *dim_in* is the number of features in the training instances (*L* in Marsland). Hence we can read *dim_in* off from *X_train*. Similarly, we can read *dim_out* off from *t_train*. Beware that *t_train* must be given the form of *P x dim_out* at some point, cf. the \"one-vs-all\" exercise above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_in = X_train.shape[1]\n",
    "dim_out = len(set(t_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need two sets of weights: weights1 between the input and the hidden layer, and weights2, between the hidden layer and the output. Make the weight matrices and initialize them to small random numbers. Make sure that you take the bias terms into consideration and get the correct dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have dim_in = 2 and dim_out = 3, while hidden layer will have 6. \n",
    "# So we need to have: 2-> 6 -> 3\n",
    "weights1 = np.random.rand(dim_in, dim_hidden) # between input and the hidden layer\n",
    "weights2 = np.random.rand(dim_hidden, dim_out) # between hidden layer and the output\n",
    "\n",
    "bias1 = np.zeros(dim_hidden)\n",
    "bias2 = np.zeros(dim_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forwards phase\n",
    "We will run the first step in the training, and start with the forward phase. Calculate the activations after the hidden layer and after the output layer. We will follow Marsland and use the logistic (sigmoid) activation function in both layers. Inspect whether the results seem reasonable with respect to format and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 6)\n",
      "[[0.66235208 0.62961145 0.64815942 0.6220043  0.66680629 0.53634958]\n",
      " [0.69282244 0.64868947 0.68182936 0.64941095 0.70219242 0.54583179]\n",
      " [0.61994212 0.58334034 0.61964294 0.5960536  0.63187444 0.53000931]\n",
      " ...\n",
      " [0.58927487 0.57104889 0.58068259 0.5660514  0.5915198  0.51935766]\n",
      " [0.68292139 0.64311328 0.67029578 0.64007013 0.69026475 0.54248465]\n",
      " [0.64432604 0.60971846 0.63611708 0.61097583 0.65204923 0.53366625]]\n"
     ]
    }
   ],
   "source": [
    "hidden_activations = logistic((X_train_scaled @ weights1) + bias1)\n",
    "print(hidden_activations.shape)\n",
    "print(hidden_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 3)\n",
      "[[0.83485071 0.86690096 0.85687126]\n",
      " [0.84469035 0.87465429 0.8656377 ]\n",
      " [0.82458725 0.85721891 0.84548208]\n",
      " ...\n",
      " [0.81260125 0.84821643 0.83530578]\n",
      " [0.84141552 0.87212028 0.86278884]\n",
      " [0.83055888 0.8628501  0.8521123 ]]\n"
     ]
    }
   ],
   "source": [
    "output_activations = logistic((hidden_activations @ weights2) + bias2)\n",
    "print(output_activations.shape)\n",
    "print(output_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backwards phase\n",
    "Calculate the delta terms at the output. We assume, like Marsland, that we use sums of squared errors. (This amounts to the same as using the mean square error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train_new = np.zeros((len(X_train[:,0]), dim_out))\n",
    "t_train_new[t_train == 0] = [1,0,0]\n",
    "t_train_new[t_train == 1] = [0,1,0]\n",
    "t_train_new[t_train == 2] = [0,0,1]\n",
    "# print(t_train_new[:20])\n",
    "# print(t_train[:20])\n",
    "\n",
    "# From formula page 78-79 in Marsland\n",
    "output_error = (output_activations - t_train_new)*output_activations*(1-output_activations)\n",
    "# !!! IF (output_activations - t_train_new) so we need to have -= on weigths2 and not +\n",
    "# However if we have (t_train_new - output_activations) we need to have + on wieghts2 change and not -\n",
    "# And also results better with same (- or +) on weights1\n",
    "\n",
    "# output_error = (t_train_new - output_activations)*output_activations*(1-output_activations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the delta terms in the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_error = hidden_activations * (1-hidden_activations)*(output_error @ weights2.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the weights.\n",
    "Check that they have changed.\n",
    "As the weights depend on the random initialization, there is no unique correct solution at this point. But you should be able to see that the weights have been updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 += eta * (X_train_scaled.T @ hidden_error) # between input and the hidden layer\n",
    "weights2 -= eta * (hidden_activations.T @ output_error) # between hidden layer and the output\n",
    "\n",
    "# print(weights1)\n",
    "# print(weights2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 2: A Multi-layer neural network classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to train and test a classifier on (X, t). You could have put some parts of the code in the last step into a loop and run it through some iterations. But instead of copying code for every network we want to train, we will build a general Multi-layer neural network classfier as a class. This class will have some of the same structure as the classifiers we made for linear and logistic regression. The task consists mainly in copying in parts from what you did in step 1 into the template below. Remember to add the *self*- prefix where needed, and be careful in your use of variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNNClassifier():\n",
    "    \"\"\"A multi-layer neural network with one hidden layer\"\"\"\n",
    "    \n",
    "    def __init__(self,eta = 0.001, dim_hidden = 6):\n",
    "        \"\"\"Initialize the hyperparameters\"\"\"\n",
    "        self.eta = eta\n",
    "        self.dim_hidden = dim_hidden\n",
    "\n",
    "        # Should you put additional code here?\n",
    "        # Not really, because I can define self. variables in other functions.\n",
    "        # However by defining it here and puting value to None, I would make it \n",
    "        # more safe, i guess\n",
    "        # In my case If I am not defining any more self. so I need to be careful,\n",
    "        # because I must not use intanse variables before defining them.\n",
    "        \n",
    "    def fit(self, X_train, t_train, epochs = 100):\n",
    "        \"\"\"Initialize the weights. Train *epochs* many epochs.\"\"\"\n",
    "        \n",
    "        # Initilaization\n",
    "        self.dim_in =  X_train.shape[1]\n",
    "        self.dim_out = len(set(t_train))\n",
    "        \n",
    "        # 1/sqrt(dim_in) from Marsland book recommendation\n",
    "        # between input and the hidden layer\n",
    "        self.weights1 = np.random.rand(self.dim_in, self.dim_hidden)*(1/np.sqrt(self.dim_in))\n",
    "        # between hidden layer and the output\n",
    "        self.weights2 = np.random.rand(self.dim_hidden, self.dim_out)*(1/np.sqrt(self.dim_in))\n",
    "\n",
    "        self.bias1 = np.zeros(self.dim_hidden)\n",
    "        self.bias2 = np.zeros(self.dim_out)\n",
    "        \n",
    "        t_train_new = np.zeros((X_train.shape[0], self.dim_out))\n",
    "        if self.dim_out == 2:\n",
    "            t_train_new[t_train == 0] = [1,0]\n",
    "            t_train_new[t_train == 1] = [0,1]\n",
    "        else:\n",
    "            t_train_new[t_train == 0] = [1,0,0]\n",
    "            t_train_new[t_train == 1] = [0,1,0]\n",
    "            t_train_new[t_train == 2] = [0,0,1]\n",
    "        self.t_train_new = t_train_new\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            # Run one epoch of forward-backward\n",
    "            self.hidden_activations, self.output_activations = self.forward(X_train)\n",
    "            self.backward(X_train)\n",
    "\n",
    "            \n",
    "    def forward(self, X):\n",
    "        \"\"\"Perform one forward step. \n",
    "        Return a pair consisting of the outputs of the hidden_layer\n",
    "        and the outputs on the final layer\"\"\"\n",
    "        hidden_activations = logistic((X @ self.weights1) + self.bias1)\n",
    "        output_activations = logistic((hidden_activations @ self.weights2) + self.bias2)\n",
    "        return hidden_activations, output_activations\n",
    "    \n",
    "    def backward(self, X):\n",
    "        output_error = (self.output_activations - self.t_train_new)*self.output_activations*(1-self.output_activations)\n",
    "        hidden_error = self.hidden_activations * (1-self.hidden_activations)*(output_error @ self.weights2.T)\n",
    "        \n",
    "        self.weights1 -= eta * (X.T @ hidden_error) # between input and the hidden layer\n",
    "        self.weights2 -= eta * (self.hidden_activations.T @ output_error) # between hidden layer and the output\n",
    "        \n",
    "        self.bias1 = self.eta * np.sum(hidden_error, axis=0)\n",
    "        self.bias2 = self.eta * np.sum(output_error, axis=0, keepdims=True)\n",
    "\n",
    "    def accuracy(self, X_test, y_test, **kwargs):\n",
    "        \"\"\"Calculate the accuracy of the classifier on the pair (X_test, t_test)\n",
    "        Return the accuracy\"\"\"\n",
    "        predicted = [self.predict(a, **kwargs) for a in X_test]\n",
    "        equal = len([(p, g) for (p, g) in zip(predicted, y_test) if p==g])\n",
    "        return equal / len(y_test)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the value for the item x\"\"\"\n",
    "        hid, out = self.forward(X)\n",
    "        return out.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network on (X_train, t_train) (after scaling), and test on (X_val, t_val). Adjust hyperparameters or number of epochs if you are not content with the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5675\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "x_max = np.max(X_train)\n",
    "x_min = np.min(X_train)\n",
    "X_train_scaled = (X_train - x_min)/(x_max - x_min)\n",
    "\n",
    "maxList = []\n",
    "for _ in range(1): # can change range to neede value, to check the max accuracy from many runs\n",
    "    mnn = MNNClassifier(0.01, 6)\n",
    "    mnn.fit(X_train_scaled, t_train, 5000)\n",
    "\n",
    "    # Test\n",
    "    x_max = np.max(X_val)\n",
    "    x_min = np.min(X_val)\n",
    "    X_val_scaled = (X_val - x_min)/(x_max - x_min)\n",
    "    acc = mnn.accuracy(X_val_scaled, t_val)\n",
    "    maxList.append(acc)\n",
    "\n",
    "print(max(maxList))\n",
    "# Got 0.675 (1000 epochs, 0.01 learning rate)\n",
    "# Got 0.75  (5000 epochs, 0.01 learning rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a neural network classifier for (X,t)\n",
    "Let us see whether a multilayer neural network can learn a non-linear classifier.\n",
    "Train it on (X_train, t_train) and test it on (X_val, t_val).\n",
    "Tune the hyper-parameters for the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n"
     ]
    }
   ],
   "source": [
    "# Wasn't sure what I had to do. So I just tried to letneural network learn without scaling anything\n",
    "maxList = []\n",
    "for _ in range(1):\n",
    "    mnn = MNNClassifier(0.01, 6)\n",
    "    mnn.fit(X_train, t_train, 5000)\n",
    "\n",
    "    maxList.append(mnn.accuracy(X_val, t_val))\n",
    "\n",
    "print(max(maxList))\n",
    "\n",
    "# Got 0.7475 (1000 epochs, 0.01 learning rate)\n",
    "# Got 0.7525 (5000 epochs, 0.01 learning rate)\n",
    "\n",
    "# Feels like Neural network worsk better without scaling (in avarage). Maybe it is how it is supposed \n",
    "# to be or I just did something wrong in scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For master's students: Early stopping\n",
    "There is a danger of overfitting if we run too many epochs of training. One way to control that is to use early stopping. We can use (X_val, t_val) as valuation set when training on (X_train, t_train).\n",
    "\n",
    "Let *e=50* or *e=10* (You may try both or choose some other number) After *e* number of epochs, calculate the loss for both the training set (X_train, t_train) and the validation set (X_val, t_val), and plot them as in figure 4.11 in Marsland. \n",
    "\n",
    "Modify the code so that the training stops if the loss on the validation set is not reduced by more than *t* after *e* many epochs, where *t* is a threshold you provide as a parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Final testing\n",
    "Take the best classifiers that you found for the training sets (X, t) and (X, t2) and test them on (X_test, t_test) and (X_test, t2_test), respectively. Compute accuracy, the confusion matrix, precision and recall. Answer in 2-3 sentences: How do the accuracies compare to the results on the validation sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN: (X,t) (X_test, t_test)\n",
      "Accuracy = 0.7475 \n",
      "\n",
      "         Predicted  \n",
      "       [69. 23.  0.]\n",
      "Actual [ 10. 159.  26.]\n",
      "       [ 0. 42. 71.]\n",
      "Class 0 Precision: 0.8734177215189873 Recall: 0.75\n",
      "Class 1 Precision: 0.7098214285714286 Recall: 0.8153846153846154\n",
      "Class 2 Precision: 0.7319587628865979 Recall: 0.6283185840707964\n",
      "\n",
      "kNN: (X,t2) (X_test, t2_test)\n",
      "Accuracy = 0.75 \n",
      "\n",
      "         Predicted  \n",
      "       [141.  64.]\n",
      "Actual [ 36. 159.]\n",
      "Class 0 Precision: 0.7966101694915254 Recall: 0.6878048780487804\n",
      "Class 1 Precision: 0.7130044843049327 Recall: 0.8153846153846154\n",
      "\n",
      "MNN: (X,t) (X_test, t_test)\n",
      "Accuracy = 0.6575 \n",
      "\n",
      "         Predicted  \n",
      "       [72. 20.  0.]\n",
      "Actual [ 10. 185.   0.]\n",
      "       [  0. 107.   6.]\n",
      "Class 0 Precision: 0.8780487804878049 Recall: 0.782608695652174\n",
      "Class 1 Precision: 0.592948717948718 Recall: 0.9487179487179487\n",
      "Class 2 Precision: 1.0 Recall: 0.05309734513274336\n",
      "\n",
      "MNN: (X,t2) (X_test, t2_test)\n",
      "Accuracy = 0.6325 \n",
      "\n",
      "         Predicted  \n",
      "       [ 72. 133.]\n",
      "Actual [ 14. 181.]\n",
      "Class 0 Precision: 0.8372093023255814 Recall: 0.35121951219512193\n",
      "Class 1 Precision: 0.5764331210191083 Recall: 0.9282051282051282\n"
     ]
    }
   ],
   "source": [
    "# I think KNN and MNN did very well. Also linear regression did well with extra features.\n",
    "# However I will only take KNN and MNN\n",
    "\n",
    "def cf_matrix(actual, predicted):\n",
    "    K = len(np.unique(actual))\n",
    "    matrix = np.zeros((K,K))\n",
    "    for i in range(len(actual)):\n",
    "        matrix[actual[i], predicted[i]] += 1\n",
    "\n",
    "    print(\"         Predicted  \")\n",
    "    print(f\"       {matrix[0]}\")\n",
    "    print(f\"Actual {matrix[1]}\")\n",
    "    if len(matrix) > 2:\n",
    "        print(f\"       {matrix[2]}\")\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def precision(matrix):\n",
    "    \"\"\"Makes list of the precision values\"\"\"\n",
    "    precList = []\n",
    "    classIndex = 0\n",
    "    for x in matrix.T:\n",
    "        if sum(x) != 0:\n",
    "            precList.append(x[classIndex]/sum(x))\n",
    "        else:\n",
    "            precList.append(float(0))\n",
    "        classIndex += 1\n",
    "    return precList\n",
    "\n",
    "def recall(matrix):\n",
    "    \"\"\"Makes list of the recall values\"\"\"\n",
    "    recallList = []\n",
    "    classIndex = 0\n",
    "    for x in matrix:\n",
    "        if sum(x) != 0: # to prevent NaN float\n",
    "            recallList.append(x[classIndex]/sum(x))\n",
    "        else:\n",
    "            recallList.append(float(0))\n",
    "        classIndex += 1\n",
    "    return recallList\n",
    "\n",
    "def print_precision_recall(matrix):\n",
    "    \"\"\"Prints out Precision and Recall values for each class\"\"\"\n",
    "    precisionList = precision(confMatrix)\n",
    "    recallList = recall(confMatrix)\n",
    "    for i in range(len(precisionList)):\n",
    "        print(f\"Class {i} Precision: {precisionList[i]} Recall: {recallList[i]}\")\n",
    "        \n",
    "        \n",
    "def normal(X):\n",
    "    x_max = np.max(X)\n",
    "    x_min = np.min(X)\n",
    "    X_scaled = (X - x_min)/(x_max - x_min)\n",
    "    return X_scaled\n",
    "\n",
    "# KNN\n",
    "print(\"kNN: (X,t) (X_test, t_test)\")\n",
    "cls = PykNNClassifier(k=14) # from test above I know that best accuracy at k = 14\n",
    "cls.fit(X_train.tolist(), t_train.tolist())\n",
    "acc_test = cls.accuracy(X_test.tolist(), t_test.tolist())\n",
    "print(\"Accuracy =\", acc_test, \"\\n\")\n",
    "predicted = [cls.predict(a) for a in X_test]\n",
    "confMatrix = cf_matrix(t_test, predicted)\n",
    "print_precision_recall(confMatrix)\n",
    "\n",
    "print(\"\\nkNN: (X,t2) (X_test, t2_test)\")\n",
    "cls = PykNNClassifier(k=14) # from test above I know that best accuracy at k = 14\n",
    "cls.fit(X_train.tolist(), t2_train.tolist())\n",
    "acc_test = cls.accuracy(X_test.tolist(), t2_test.tolist())\n",
    "print(\"Accuracy =\", acc_test, \"\\n\")\n",
    "predicted = [cls.predict(a) for a in X_test]\n",
    "confMatrix = cf_matrix(t2_test, predicted)\n",
    "print_precision_recall(confMatrix)\n",
    "\n",
    "\n",
    "# MNN\n",
    "print(\"\\nMNN: (X,t) (X_test, t_test)\")\n",
    "mnn = MNNClassifier(0.01, 6)\n",
    "mnn.fit(normal(X_train), t_train, 5000)\n",
    "acc_test = mnn.accuracy(normal(X_test), t_test)\n",
    "print(\"Accuracy =\", acc_test, \"\\n\")\n",
    "predicted = [mnn.predict(a) for a in normal(X_test)]\n",
    "confMatrix = cf_matrix(t_test, predicted)\n",
    "print_precision_recall(confMatrix)\n",
    "\n",
    "print(\"\\nMNN: (X,t2) (X_test, t2_test)\")\n",
    "mnn = MNNClassifier(0.01, 6)\n",
    "mnn.fit(normal(X_train), t2_train, 5000)\n",
    "acc_test = mnn.accuracy(normal(X_test), t2_test)\n",
    "print(\"Accuracy =\", acc_test, \"\\n\")\n",
    "predicted = [mnn.predict(a) for a in normal(X_test)]\n",
    "confMatrix = cf_matrix(t2_test, predicted)\n",
    "print_precision_recall(confMatrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracies from validation sets and test sets are almost the same. So it is kind of easy to predict how good accuracy we will get on test sets, without even running test sets, only by checking accuracy on validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
